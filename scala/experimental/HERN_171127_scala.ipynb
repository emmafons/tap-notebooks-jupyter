{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflecting, writing, and analytics: What can we learn from student text as data?\n",
    "### HERN Workshop - 27 Nov 2017\n",
    "\n",
    "What does a studentsâ€™ language say about their learning? When they put their personal thoughts into words, what does it reveal about them, their thinking, and their interactions with others? In this workshop we will explore some of the ways reflective writing can be used for learning, and take an introductory look at how we can discover meaningful aspects of the writing through computational analysis. During the workshop, we will experiment with a couple of tools for analysing writing, examine some cases of how these tools were used for learning, and we will establish some important principles for using writing analytics in a learning and teaching context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A couple of RWA examples \n",
    "\n",
    "#### Academic Reflective Writing\n",
    "\n",
    "[Academic Writing Analytics (AWA)](http://awa.uts.edu.au/) \n",
    "\n",
    "- Login using AAF\n",
    "- Try examplar reflections\n",
    "- Look at the theoretical framework for reflective writing\n",
    "- Examine how the framework links throught to the feedback\n",
    "\n",
    "#### Reflection and Metacognition\n",
    "\n",
    "[Towards the Discovery of Learner Metacognition From Reflective Writing](http://nlytx.io/2016/metacognition/index.html) \n",
    "\n",
    "- Try different examples and view the features\n",
    "- Look at the theoretical link between metacognition and reflection\n",
    "- Examine how the theory translates to the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY Reflective Writing Analytics\n",
    "\n",
    "A basic Reflective Writing Analytics (RWA) task, step by step using the [Text Analytics Pipeline (TAP)](http://tap-test.utscic.edu.au)\n",
    "\n",
    "#### The Task - Group Efficacy\n",
    "\n",
    "Consider a large cohort of students undertaking an assignment in small groups. Most work is undertaken outside of face-to-face time, and therefore monitoring group interaction is not practical.\n",
    "\n",
    "Suppose we wish to identify which groups are functioning well and which groups are having problems so that we can intervene early.\n",
    "\n",
    "**The Writing:** *Students use [GoingOK](http://goingok.org) to write short personal reflections about their group work after each group interaction (or at least once per week).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] Setup code necessary to do our analytics\n",
    "\n",
    "Before we can actually perform the analytics, we need import some additional software and setup some helper functions. The following code block does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.scalaj:scalaj-http_2.11:2.3.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps244737840313834164/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps244737840313834164/https/repo1.maven.org/maven2/org/scalaj/scalaj-http_2.11/2.3.0/scalaj-http_2.11-2.3.0.jar\n",
      "Marking org.json4s:json4s-jackson_2.11:3.5.3 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps244737840313834164/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree_add_deps244737840313834164/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.11/3.5.3/json4s-jackson_2.11-3.5.3.jar\n"
     ]
    }
   ],
   "source": [
    "/* DEPENDENCIES */\n",
    "\n",
    "//Load additional software to make a web connection to TAP and decode the JSON response\n",
    "%AddDeps org.scalaj scalaj-http_2.11 2.3.0\n",
    "%AddDeps org.json4s json4s-jackson_2.11 3.5.3\n",
    "\n",
    "//Import the libraries that we are going to use into this notebook\n",
    "import scalaj.http._                            // Handle web connection to TAP\n",
    "import org.json4s._                             // Encode and decode JSON\n",
    "import org.json4s.jackson.JsonMethods._\n",
    "import scala.io.Source                          // Read from filesystem\n",
    "import org.apache.toree.magic.{CellMagicOutput, CellMagic}   //Display custom HTML in the notebook\n",
    "import org.apache.toree.kernel.protocol.v5.{Data, MIMEType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "/* HELPER FUNCTIONS */\n",
    "\n",
    "// Get a list of lines (paragraphs) from a text file in the example_text directory\n",
    "def getLinesFromFile(name: String) = Source.fromFile(s\"example_text/$name\").getLines.toList\n",
    "\n",
    "// Output HTML to the notebook after current cell\n",
    "def displayHtml(html: String) = Left(CellMagicOutput(MIMEType.TextHtml -> html))\n",
    "\n",
    "// Output list of strings with index and separator\n",
    "def printOut(list:List[String],label:String=\"\"): Unit = {\n",
    "    val indexed = list.zipWithIndex\n",
    "    indexed.foreach { case (str,idx) =>\n",
    "        println(s\"\\n---[$label ${idx+1}]--------------------------------\\n\")\n",
    "        println(str)\n",
    "    }\n",
    "}\n",
    "\n",
    "// Build a GraphQL query from TAP query and input text\n",
    "def buildGraphQlQuery(input:String,query:String)= {\n",
    "    import org.json4s.JsonDSL._\n",
    "    val variables = (\"input\" -> input)\n",
    "    val fullQuery = (\"query\" -> query) ~ (\"variables\" -> variables)\n",
    "    compact(render(fullQuery))\n",
    "}\n",
    "\n",
    "// The data structures for analytics from TAP\n",
    "case class Token(idx:Int,term:String,lemma:String,postag:String)\n",
    "case class Analytic(idx:Int,tokens:List[Token])\n",
    "\n",
    "// Post query to TAP Url and return Analytic object for each sentence\n",
    "def getAnalytics(server:String,query:String):List[Analytic] = {\n",
    "    val url = s\"http://$server/graphql\" //The URL - graphql endpoint at server\n",
    "    val queryRequest = Http(url).postData(query).header(\"content-type\", \"application/json\") //The request\n",
    "    val queryData = parse(queryRequest.asString.body)\n",
    "    implicit val formats = DefaultFormats                 // An implicit allows extraction to scala Ojbect from JValue\n",
    "    (queryData \\ \"data\" \\ \"annotations\" \\ \"analytics\").extract[List[Analytic]]\n",
    "}\n",
    "\n",
    "// Extraction and HTML markup of personal pronouns\n",
    "object Pronouns {\n",
    "    \n",
    "    def extractPersonal(analytics:List[Analytic]):List[String] = {\n",
    "        analytics.flatMap( _.tokens.filter(_.postag.contains(\"PRP\")).map(_.term))\n",
    "    }\n",
    "\n",
    "    def otherOne(term:String) = List(\"he\",\"him\",\"his\",\"she\",\"her\",\"hers\").contains(term.toLowerCase)\n",
    "    def others(term:String) = List(\"them\",\"they\",\"theirs\").contains(term.toLowerCase)\n",
    "    def group(term:String) = List(\"we\",\"us\",\"our\").contains(term.toLowerCase)\n",
    "    def self(term:String) = List(\"i\",\"me\",\"my\").contains(term.toLowerCase)\n",
    "\n",
    "    def wrap(term:String,id:String) = s\"\"\"<span class=\"$id\">$term</span>\"\"\"\n",
    "\n",
    "    def markupPersonal(list: List[String]): String = list match {\n",
    "        case Nil => \"\"\n",
    "        case term :: rest => {\n",
    "            val mt = term match {\n",
    "                case t if otherOne(t) => wrap(t,\"otherone\")\n",
    "                case t if others(t) => wrap(t,\"others\")\n",
    "                case t if self(t) => wrap(t,\"self\")\n",
    "                case t if group(t) => wrap(t,\"group\")\n",
    "                case t => t\n",
    "            }\n",
    "            mt + \" \" + markupPersPronouns(rest)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] Look at writing cases for language features\n",
    "\n",
    "To address our task, we need to answer a couple of questions about the writing:\n",
    "\n",
    "- *What features are we likely to see in the students writing when group work is going well?* \n",
    "- *What about when the group is not functioning?*\n",
    "\n",
    "Load example files and take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>student 1: </b>I can't believe that Harry has done nothing for our project. Everyone has been working diligently on it except him. He hasn't even started. If he doesn't lift his game this week, I'm going to talk to our tutor about it. I don't want us all to get a bad mark because he can't make an effort.</p><p><b>student 2: </b>Our group has been working really well together, and we are making good progress. Yesterday we met to discuss the tasks that need to be done and who might be best to do them. Everyone was really keen to help which is a good sign for our project. This is the first group project where everyone is dedicated, so I think we should be able to get a good mark.</p>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Load two files - Fake students from two different groups\n",
    "val file1 = getLinesFromFile(\"grp1-pers1.txt\")\n",
    "val file2 = getLinesFromFile(\"grp2-pers1.txt\")\n",
    "\n",
    "//Get the text of the first paragraph for each\n",
    "val student1 = file1.head\n",
    "val student2 = file2.head\n",
    "\n",
    "//View the text as HTML\n",
    "displayHtml(s\"<p><b>student 1: </b>$student1</p>\"+s\"<p><b>student 2: </b>$student2</p>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insignificant words that are significant\n",
    "\n",
    "Often, when processing text computationally we are interested in content, and so words that don't contribute to the content, called stop words (a, the, this, then, me, I, us), are discarded and the algorithm works with the content words.\n",
    "\n",
    "- *What do content words tell us about the effectiveness of the groups?*\n",
    "\n",
    "- *What about the stop words? Do they tell us anything?*\n",
    "\n",
    "#### Querying the Text Analytics Pipeline (TAP) \n",
    "\n",
    "To analyse the text with [TAP](http://tap-test.utscic.edu.au), we need to formulate a query for the type of analytics we want, send that query with the text to be analysed, and capture the result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[Query 1]--------------------------------\n",
      "\n",
      "{\"query\":\"\\n    query SentenceAnalysis($input: String!) {\\n      annotations(text:$input) {\\n        analytics {\\n          idx\\n          tokens {\\n            idx\\n            term\\n            lemma\\n            postag\\n          }\\n        }\\n      }\\n    }\",\"variables\":{\"input\":\"I can't believe that Harry has done nothing for our project. Everyone has been working diligently on it except him. He hasn't even started. If he doesn't lift his game this week, I'm going to talk to our tutor about it. I don't want us all to get a bad mark because he can't make an effort.\"}}\n",
      "\n",
      "---[Query 2]--------------------------------\n",
      "\n",
      "{\"query\":\"\\n    query SentenceAnalysis($input: String!) {\\n      annotations(text:$input) {\\n        analytics {\\n          idx\\n          tokens {\\n            idx\\n            term\\n            lemma\\n            postag\\n          }\\n        }\\n      }\\n    }\",\"variables\":{\"input\":\"Our group has been working really well together, and we are making good progress. Yesterday we met to discuss the tasks that need to be done and who might be best to do them. Everyone was really keen to help which is a good sign for our project. This is the first group project where everyone is dedicated, so I think we should be able to get a good mark.\"}}\n"
     ]
    }
   ],
   "source": [
    "//Formulate a query to tell TAP what analytics are wanted\n",
    "val query = \"\"\"\n",
    "    query SentenceAnalysis($input: String!) {\n",
    "      annotations(text:$input) {\n",
    "        analytics {\n",
    "          idx\n",
    "          tokens {\n",
    "            idx\n",
    "            term\n",
    "            lemma\n",
    "            postag\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\"\"\"\n",
    "\n",
    "//For convenience, put the texts in a list\n",
    "val students = List(student1,student2)\n",
    "\n",
    "//Format the query for each input text as GraphQL for TAP\n",
    "val graphQlQueries = students.map(s => buildGraphQlQuery(s,query))\n",
    "\n",
    "//View the final queries\n",
    "printOut(graphQlQueries,\"Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[Analytics 1]--------------------------------\n",
      "\n",
      "List(Analytic(0,List(Token(0,I,i,PRP), Token(1,ca,ca,MD), Token(2,n't,n't,RB), Token(3,believe,believe,VB), Token(4,that,that,IN), Token(5,Harry,harry,NNP), Token(6,has,have,VBZ), Token(7,done,do,VBN), Token(8,nothing,nothing,NN), Token(9,for,for,IN), Token(10,our,our,PRP$), Token(11,project,project,NN), Token(12,.,.,.))), Analytic(1,List(Token(0,Everyone,everyone,NN), Token(1,has,have,VBZ), Token(2,been,be,VBN), Token(3,working,work,VBG), Token(4,diligently,diligently,RB), Token(5,on,on,IN), Token(6,it,it,PRP), Token(7,except,except,IN), Token(8,him,him,PRP), Token(9,.,.,.))), Analytic(2,List(Token(0,He,he,PRP), Token(1,has,have,VBZ), Token(2,n't,n't,RB), Token(3,even,even,RB), Token(4,started,start,VBN), Token(5,.,.,.))), Analytic(3,List(Token(0,If,if,IN), Token(1,he,he,PRP), Token(2,does,do,VBZ), Token(3,n't,n't,RB), Token(4,lift,lift,VB), Token(5,his,his,PRP$), Token(6,game,game,NN), Token(7,this,this,DT), Token(8,week,week,NN), Token(9,,,,,,), Token(10,I,i,PRP), Token(11,'m,'m,VBP), Token(12,going,go,VBG), Token(13,to,to,TO), Token(14,talk,talk,VB), Token(15,to,to,IN), Token(16,our,our,PRP$), Token(17,tutor,tutor,NN), Token(18,about,about,IN), Token(19,it,it,PRP), Token(20,.,.,.))), Analytic(4,List(Token(0,I,i,PRP), Token(1,do,do,VBP), Token(2,n't,n't,RB), Token(3,want,want,VB), Token(4,us,us,PRP), Token(5,all,all,DT), Token(6,to,to,TO), Token(7,get,get,VB), Token(8,a,a,DT), Token(9,bad,bad,JJ), Token(10,mark,mark,NN), Token(11,because,because,IN), Token(12,he,he,PRP), Token(13,ca,ca,MD), Token(14,n't,n't,RB), Token(15,make,make,VB), Token(16,an,an,DT), Token(17,effort,effort,NN), Token(18,.,.,.))))\n",
      "\n",
      "---[Analytics 2]--------------------------------\n",
      "\n",
      "List(Analytic(0,List(Token(0,Our,our,PRP$), Token(1,group,group,NN), Token(2,has,have,VBZ), Token(3,been,be,VBN), Token(4,working,work,VBG), Token(5,really,really,RB), Token(6,well,well,RB), Token(7,together,together,RB), Token(8,,,,,,), Token(9,and,and,CC), Token(10,we,we,PRP), Token(11,are,be,VBP), Token(12,making,make,VBG), Token(13,good,good,JJ), Token(14,progress,progress,NN), Token(15,.,.,.))), Analytic(1,List(Token(0,Yesterday,yesterday,NN), Token(1,we,we,PRP), Token(2,met,meet,VBD), Token(3,to,to,TO), Token(4,discuss,discuss,VB), Token(5,the,the,DT), Token(6,tasks,task,NNS), Token(7,that,that,WDT), Token(8,need,need,VBP), Token(9,to,to,TO), Token(10,be,be,VB), Token(11,done,do,VBN), Token(12,and,and,CC), Token(13,who,who,WP), Token(14,might,might,MD), Token(15,be,be,VB), Token(16,best,best,JJS), Token(17,to,to,TO), Token(18,do,do,VB), Token(19,them,them,PRP), Token(20,.,.,.))), Analytic(2,List(Token(0,Everyone,everyone,NN), Token(1,was,be,VBD), Token(2,really,really,RB), Token(3,keen,keen,JJ), Token(4,to,to,TO), Token(5,help,help,VB), Token(6,which,which,WDT), Token(7,is,be,VBZ), Token(8,a,a,DT), Token(9,good,good,JJ), Token(10,sign,sign,NN), Token(11,for,for,IN), Token(12,our,our,PRP$), Token(13,project,project,NN), Token(14,.,.,.))), Analytic(3,List(Token(0,This,this,DT), Token(1,is,be,VBZ), Token(2,the,the,DT), Token(3,first,first,JJ), Token(4,group,group,NN), Token(5,project,project,NN), Token(6,where,where,WRB), Token(7,everyone,everyone,NN), Token(8,is,be,VBZ), Token(9,dedicated,dedicate,VBN), Token(10,,,,,,), Token(11,so,so,CC), Token(12,I,i,PRP), Token(13,think,think,VBP), Token(14,we,we,PRP), Token(15,should,should,MD), Token(16,be,be,VB), Token(17,able,able,JJ), Token(18,to,to,TO), Token(19,get,get,VB), Token(20,a,a,DT), Token(21,good,good,JJ), Token(22,mark,mark,NN), Token(23,.,.,.))))\n"
     ]
    }
   ],
   "source": [
    "//Set the address for TAP\n",
    "val tapAddress = \"tap-test.utscic.edu.au\"\n",
    "\n",
    "//Get the analytics\n",
    "val analytics = graphQlQueries.map(q => getAnalytics(tapAddress,q))\n",
    "\n",
    "//The RAW analytics...\n",
    "printOut(analytics.map(_.toString), \"Analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[Student 1]--------------------------------\n",
      "\n",
      "I, our, it, him, He, he, his, I, our, it, I, us, he\n",
      "\n",
      "---[Student 2]--------------------------------\n",
      "\n",
      "Our, we, we, them, our, I, we\n"
     ]
    }
   ],
   "source": [
    "//Extract personal pronouns for each of these sets of analytics\n",
    "val personalPronouns = analytics.map(Pronouns.extractPersonal(_))\n",
    "\n",
    "//The final pronouns for each text\n",
    "printOut(personalPronouns.map(_.mkString(\", \")),\"Student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulating a hypothesis\n",
    "\n",
    "When performing writing analytics, we use observations coupled a knowledge of the context and relevant theory to formulate a hypothesis about how the text might be analysed to yield insights that are of practical benefit.\n",
    "\n",
    "**Hypothesis:** Is the use of singular or plural pronouns an indicator of group efficacy?\n",
    "\n",
    "We can then test this on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  .otherone { color: red;   font-weight: bold; }\n",
       "  .group    { color: green; font-weight: bold; }    \n",
       "  .self     { color: blue;  font-weight: bold; }\n",
       "  .others   { border-bottom: 2px red solid; }\n",
       "</style>\n",
       "<p><b>Student 1: </b><span class=\"self\">I</span> ca n't believe that Harry has done nothing for <span class=\"group\">our</span> project . Everyone has been working diligently on it except <span class=\"otherone\">him</span> . <span class=\"otherone\">He</span> has n't even started . If <span class=\"otherone\">he</span> does n't lift <span class=\"otherone\">his</span> game this week , <span class=\"self\">I</span> 'm going to talk to <span class=\"group\">our</span> tutor about it . <span class=\"self\">I</span> do n't want <span class=\"group\">us</span> all to get a bad mark because <span class=\"otherone\">he</span> ca n't make an effort . </p>\n",
       "<p><b>Student 2: </b><span class=\"group\">Our</span> group has been working really well together , and <span class=\"group\">we</span> are making good progress . Yesterday <span class=\"group\">we</span> met to discuss the tasks that need to be done and who might be best to do <span class=\"others\">them</span> . Everyone was really keen to help which is a good sign for <span class=\"group\">our</span> project . This is the first group project where everyone is dedicated , so <span class=\"self\">I</span> think <span class=\"group\">we</span> should be able to get a good mark . </p>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Get the terms from the analytics and markup the personal pronouns\n",
    "val markedUpTerms:List[String] = analytics.map { student => \n",
    "    val terms = student.flatMap( analytic => analytic.tokens.map(_.term))\n",
    "    Pronouns.markupPersonal(terms)\n",
    "}\n",
    "\n",
    "//Set some CSS for the HTML markup\n",
    "val css = \"\"\"\n",
    "<style>\n",
    "  .otherone { color: red;   font-weight: bold; }\n",
    "  .group    { color: green; font-weight: bold; }    \n",
    "  .self     { color: blue;  font-weight: bold; }\n",
    "  .others   { border-bottom: 2px red solid; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "//Create the final HTML Snippet and display it\n",
    "val finalText = markedUpTerms.zipWithIndex.map { case (text,idx) =>\n",
    "    s\"<p><b>Student ${idx+1}: </b>$text</p>\"\n",
    "}.mkString(\"\\n\")\n",
    "\n",
    "displayHtml(css+finalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
